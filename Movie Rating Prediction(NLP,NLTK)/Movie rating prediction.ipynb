{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Movie Rating Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfx=pd.read_csv(\"./Train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mature intelligent and highly charged melodram...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://video.google.com/videoplay?docid=211772...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Title: Opera (1987) Director: Dario Argento Ca...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I think a lot of people just wrote this off as...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This is a story of two dogs and a cat looking ...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review label\n",
       "0  mature intelligent and highly charged melodram...   pos\n",
       "1  http://video.google.com/videoplay?docid=211772...   pos\n",
       "2  Title: Opera (1987) Director: Dario Argento Ca...   pos\n",
       "3  I think a lot of people just wrote this off as...   pos\n",
       "4  This is a story of two dogs and a cat looking ...   pos"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfx.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40000, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test=pd.read_csv(\"./Test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test=df_test.values[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Remember those old kung fu movies we used to w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This movie is another one on my List of Movies...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How in the world does a thing like this get in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"Queen of the Damned\" is one of the best vampi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Caprica episode (S01E01) is well done as a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review\n",
       "0  Remember those old kung fu movies we used to w...\n",
       "1  This movie is another one on my List of Movies...\n",
       "2  How in the world does a thing like this get in...\n",
       "3  \"Queen of the Damned\" is one of the best vampi...\n",
       "4  The Caprica episode (S01E01) is well done as a..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['neg', 'pos'], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(dfx.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "neg    19989\n",
       "pos    20011\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfx.groupby(\"label\").size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=dfx.values[:,0]\n",
    "Y_train=dfx.values[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://video.google.com/videoplay?docid=211772166650071408&hl=en Distribution was tried.<br /><br />We opted for mass appeal.<br /><br />We want the best possible viewing range so, we forgo profit and continue our manual labor jobs gladly to entertain you for working yours.<br /><br />View Texas tale, please write about it... If you like it or not, if you like Alex or not, if you like Stuie, Texas or Texas tale... Just write about it.<br /><br />Your opinion rules.\n"
     ]
    }
   ],
   "source": [
    "print(X_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40000,)\n",
      "(40000,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(Y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Converting String into numbers of Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "le=LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 ... 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "Y_train=le.fit_transform(np.array(Y_train))\n",
    "print(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pos' 'pos' 'pos' ... 'neg' 'pos' 'pos']\n"
     ]
    }
   ],
   "source": [
    "print(le.inverse_transform(Y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Cleaning the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "en_stopwords = set(stopwords.words('english'))\n",
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'have', 'in', 'your', 'what', 'who', 'we', 'this', 'd', 'over', 'other', \"you'll\", 'themselves', 'just', 'and', 'how', 'itself', 'been', \"it's\", 'of', 'shan', 'here', 'mightn', 'there', 'ours', \"wasn't\", 'ma', 'when', 'few', 'to', 'they', 'only', 'ourselves', 'i', 'won', 'it', 've', 'hadn', 'against', 'yours', 'are', 'down', 'or', 'having', 'being', 'until', 'on', 'doing', 'should', \"hasn't\", \"won't\", 'yourselves', 'him', 'herself', 'were', 'again', \"isn't\", 'haven', 'off', 'where', 'wouldn', 'myself', \"that'll\", 'above', 'his', 'own', 'with', 'o', 'from', \"mightn't\", 'hers', \"needn't\", 'our', 'for', \"she's\", 'up', 'all', 'why', 'needn', 'each', 'them', 'both', 'be', \"didn't\", 'by', 'ain', 'during', \"couldn't\", 'he', \"you're\", 'do', \"doesn't\", 'as', \"haven't\", 'their', 'don', 'himself', 'a', 'but', 'about', 'an', 'had', 'no', \"you'd\", 'so', 'isn', 'can', 'under', 'aren', 'she', \"mustn't\", 'if', \"you've\", 'her', 'does', 'these', 'am', 'doesn', 'into', \"wouldn't\", 'than', 'not', 'shouldn', 'between', 'very', 'hasn', 'was', 'that', 'theirs', \"shouldn't\", \"don't\", 'my', 'll', 'through', 'such', 'will', \"shan't\", 'after', \"weren't\", 'has', 'any', 'its', 'm', \"should've\", 'nor', 'most', 'couldn', \"aren't\", 'mustn', 'me', 'is', 'below', 'those', 'y', 'weren', 'too', 'same', 'while', 'you', 'at', 'further', 're', 'before', 'some', 'more', 'wasn', 't', 'then', 'out', 'didn', 'once', 's', 'whom', 'which', 'did', 'now', 'because', 'yourself', 'the', \"hadn't\"}\n"
     ]
    }
   ],
   "source": [
    "print(en_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'have', 'in', 'your', 'what', 'who', 'we', 'this', 'd', 'over', 'other', \"you'll\", 'themselves', 'just', 'and', 'how', 'itself', 'been', \"it's\", 'of', 'shan', 'here', 'mightn', 'there', 'ours', \"wasn't\", 'ma', 'when', 'few', 'to', 'they', 'only', 'ourselves', 'i', 'won', 'it', 've', 'hadn', 'against', 'yours', 'are', 'down', 'or', 'having', 'being', 'until', 'on', 'doing', 'should', \"hasn't\", \"won't\", 'yourselves', 'him', 'herself', 'were', 'again', \"isn't\", 'haven', 'off', 'where', 'wouldn', 'myself', \"that'll\", 'above', 'his', 'own', 'with', 'o', 'from', \"mightn't\", 'hers', \"needn't\", 'our', 'for', \"she's\", 'up', 'all', 'why', 'needn', 'each', 'them', 'both', 'be', \"didn't\", 'by', 'ain', 'during', \"couldn't\", 'he', \"you're\", 'do', \"doesn't\", 'as', \"haven't\", 'their', 'don', 'himself', 'a', 'but', 'about', 'an', 'had', \"you'd\", 'so', 'isn', 'can', 'under', 'aren', 'she', \"mustn't\", 'if', \"you've\", 'her', 'does', 'these', 'am', 'doesn', 'into', \"wouldn't\", 'than', 'shouldn', 'between', 'very', 'hasn', 'was', 'that', 'theirs', \"shouldn't\", \"don't\", 'my', 'll', 'through', 'such', 'will', \"shan't\", 'after', \"weren't\", 'has', 'any', 'its', 'm', \"should've\", 'nor', 'most', 'couldn', \"aren't\", 'mustn', 'me', 'is', 'below', 'those', 'y', 'weren', 'too', 'same', 'while', 'you', 'at', 'further', 're', 'before', 'some', 'more', 'wasn', 't', 'then', 'out', 'didn', 'once', 's', 'whom', 'which', 'did', 'now', 'because', 'yourself', 'the', \"hadn't\"}\n"
     ]
    }
   ],
   "source": [
    "# Removing not from stopwords so that it can be used for generating better review\n",
    "# Ex: Not good - will be treated as false\n",
    "# Ex: Not bad - will be treated as true\n",
    "# so bigram will be used for this purpose\n",
    "\n",
    "en_stopwords.remove(\"no\")\n",
    "en_stopwords.remove(\"not\")\n",
    "print(en_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re   # used for regular expression or you can use nltk RegexpTokenizer\n",
    "from bs4 import BeautifulSoup as bs     # used to remove HTML tags\n",
    "\n",
    "def clean(text):\n",
    "    no_html = bs(text).get_text()\n",
    "    clean = re.sub(\"[^a-z\\s]+\", \" \", no_html, flags=re.IGNORECASE)\n",
    "    return re.sub(\"(\\s+)\", \" \", clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "ps = PorterStemmer()\n",
    "def tokenize(text):\n",
    "    clean_ = clean(text).lower()\n",
    "    stemmed_tokens = [ps.stem(token) for token in clean_.split()]\n",
    "    cl=[w for w in stemmed_tokens if not w in en_stopwords]\n",
    "    return (\" \".join(cl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def cleaning_reviews(review):\n",
    "    \n",
    "#     review=review.lower()\n",
    "    \n",
    "#     review = review.replace(\"<br /><br />\",\" \")\n",
    "    \n",
    "#     tokens=tokenizer.tokenize(review)\n",
    "    \n",
    "#     new_tokens = [token for token in tokens if token not in en_stopwords]\n",
    "    \n",
    "#     stemmed_tokens = [ps.stem(token) for token in new_tokens]\n",
    "    \n",
    "#     cleaned_review = ' '.join(stemmed_tokens)\n",
    "    \n",
    "#     return cleaned_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mature intelligent and highly charged melodrama unbelivebly filmed in China in 1948. wei wei's stunning performance as the catylast in a love triangle is simply stunning if you have the oppurunity to see this magnificent film take it\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'matur intellig highli charg melodrama unbelivebl film china wei wei stun perform catylast love triangl simpli stun oppurun see thi magnific film take'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X_train[0])\n",
    "tokenize(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "All_cleaned_reviews=[tokenize(X_train[i]) for i in range(X_train.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First of all i want to say Ang Lee Did a very good job on this one! I watched it yesterday and i was presently surprised. The story is very good, but all the ignorant people would say \"This sucks people cant fly!\" to them i say IT'S FICTION and that it is. This is not to be taken as a film about reality you could say this is a \"fairytale\". And a very pleasant to watch Asian fairytale. The image's can actually blow your mind. Because there so artistically filmed , Ang Lee has a very (unapreciated u might say) big talent. The fight scene's are very cool and beautifully brought to the viewer. But it's sad but this film didn't get the appreciation it should have gotten. But Ang Lee did fortunately get the attention he deserved with his blockbuster broke back mountain. So even for viewers who are not interested in the story the images are entertaining enough!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'first want say ang lee veri good job thi one watch yesterday wa present surpris stori veri good ignor peopl would say thi suck peopl cant fli say fiction thi not taken film realiti could say thi fairytal veri pleasant watch asian fairytal imag actual blow mind becaus artist film ang lee ha veri unapreci u might say big talent fight scene veri cool beauti brought viewer sad thi film get appreci gotten ang lee fortun get attent deserv hi blockbust broke back mountain even viewer not interest stori imag entertain enough'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X_train[125])\n",
    "All_cleaned_reviews[125]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Vectorizing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv=CountVectorizer(ngram_range=(1,2))\n",
    "tfidf=TfidfVectorizer(ngram_range=(1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40000, 2207176)\n"
     ]
    }
   ],
   "source": [
    "X_vector=cv.fit_transform(All_cleaned_reviews) ### has given 87% accuracy\n",
    "print(X_vector.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_vector=tfidf.fit_transform(All_cleaned_reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. cleaning Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_test_reviews=[tokenize(X_test[i]) for i in range(X_test.shape[0])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Vectorization on test case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 2207176)\n"
     ]
    }
   ],
   "source": [
    "X_test_vector=cv.transform(cleaned_test_reviews)\n",
    "X_test_vector = tfidf.transform(cleaned_test_reviews)\n",
    "print(X_test_vector.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Building training model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB,BernoulliNB, GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n"
     ]
    }
   ],
   "source": [
    "mnb = MultinomialNB()\n",
    "print(mnb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb.fit(tf_vector,Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predictions\n",
    "predict=mnb.predict(X_test_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 1, 1, 0])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction=le.inverse_transform(predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['neg', 'neg', 'neg', ..., 'pos', 'pos', 'neg'], dtype=object)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    1,    2, ..., 9997, 9998, 9999])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Id=np.arange(0,X_test.shape[0])\n",
    "Id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Converting to CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe=pd.DataFrame({\"Id\":Id,\"label\":prediction})\n",
    "dataframe.to_csv(\"submission.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting 87% Accuracy With Countvectorizer\n",
    "### Getting 88% Accuracy with tfiDfVectorizer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
